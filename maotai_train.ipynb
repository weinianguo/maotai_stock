{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dropout, Dense, LSTM\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import math\n",
    "\n",
    "\n",
    "maotai = pd.read_csv('./SH600519.csv')\n",
    "training_set = maotai.iloc[0:5335 - 300, 2:3].values  # 前(2426-300=2126)天的开盘价作为训练集,表格从0开始计数，2:3 是提取[2:3)列，前闭后开,故提取出C列开盘价\n",
    "test_set = maotai.iloc[5335 - 300:, 2:3].values  # 后300天的开盘价作为测试集\n",
    "\n",
    "#归一化\n",
    "sc = MinMaxScaler(feature_range=(0, 1))  # 定义归一化：归一化到(0，1)之间\n",
    "training_set_scaled = sc.fit_transform(training_set)  # 求得训练集的最大值，最小值这些训练集固有的属性，并在训练集上进行归一化\n",
    "test_set_scaled = sc.transform(test_set) \n",
    "\n",
    "#创建时序数据，用前时刻数据预测后面的数据\n",
    "def create_dataset(dataset, time_step=60):  #适用于二维度的数据\n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-time_step-1):\n",
    "\t\tx = dataset[i:(i+time_step)]  \n",
    "\t\ty = dataset[i:(i+time_step)]\n",
    "\t\tdataX.append(x)\n",
    "\t\tdataY.append(dataset[i + time_step, 0])\n",
    "\treturn np.array(dataX), np.array(dataY)\n",
    "\n",
    "train_x, train_y = create_dataset(training_set_scaled)\n",
    "test_x, test_y = create_dataset(test_set_scaled)\n",
    "\n",
    "#模型搭建\n",
    "model = tf.keras.Sequential([\n",
    "    LSTM(80, return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    LSTM(100),\n",
    "    Dropout(0.2),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "              loss='mean_squared_error')  # 损失函数用均方误差\n",
    "\n",
    "checkpoint_save_path = \"./checkpoint/LSTM_stock.ckpt\"\n",
    "if os.path.exists(checkpoint_save_path + '.index'):\n",
    "    print('-------------load the model-----------------')\n",
    "    model.load_weights(checkpoint_save_path)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_save_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 save_best_only=True,\n",
    "                                                 monitor='val_loss')\n",
    "#数据的拟合和训练\n",
    "history = model.fit(train_x, train_y, batch_size=64, epochs=500, validation_data=(test_x, test_y), validation_freq=1,\n",
    "                    callbacks=[cp_callback])\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
