{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76d6ac7c-ba23-4eda-9774-4b5513429ce4",
   "metadata": {},
   "source": [
    "# 多变量股价预测-LSTM\n",
    "训练集时间范围：2001-01-25到2021-09-29,预测目标列为Open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27e86681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "347dedca-ce7a-4bc7-8d40-f190d03968b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9a0150-3669-4d1d-8b2d-cd9e0ef5e1b6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 数据探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59a416cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"train.csv\",parse_dates=[\"Date\"],index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d69a828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5203, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(df.index.freq)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fe6f18e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001-01-25</th>\n",
       "      <td>356.730774</td>\n",
       "      <td>362.980774</td>\n",
       "      <td>352.403839</td>\n",
       "      <td>353.365387</td>\n",
       "      <td>197.122452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-26</th>\n",
       "      <td>357.211548</td>\n",
       "      <td>360.096161</td>\n",
       "      <td>342.788452</td>\n",
       "      <td>343.269226</td>\n",
       "      <td>191.490234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-29</th>\n",
       "      <td>345.153839</td>\n",
       "      <td>355.769226</td>\n",
       "      <td>338.461548</td>\n",
       "      <td>341.384613</td>\n",
       "      <td>190.439011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-30</th>\n",
       "      <td>344.307678</td>\n",
       "      <td>355.923065</td>\n",
       "      <td>341.692322</td>\n",
       "      <td>355.769226</td>\n",
       "      <td>198.463318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-31</th>\n",
       "      <td>359.615387</td>\n",
       "      <td>361.153839</td>\n",
       "      <td>350.461548</td>\n",
       "      <td>353.692322</td>\n",
       "      <td>197.304749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close\n",
       "Date                                                                  \n",
       "2001-01-25  356.730774  362.980774  352.403839  353.365387  197.122452\n",
       "2001-01-26  357.211548  360.096161  342.788452  343.269226  191.490234\n",
       "2001-01-29  345.153839  355.769226  338.461548  341.384613  190.439011\n",
       "2001-01-30  344.307678  355.923065  341.692322  355.769226  198.463318\n",
       "2001-01-31  359.615387  361.153839  350.461548  353.692322  197.304749"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "750dae9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-09-23</th>\n",
       "      <td>99.529999</td>\n",
       "      <td>104.080002</td>\n",
       "      <td>99.519997</td>\n",
       "      <td>102.959999</td>\n",
       "      <td>102.789993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-24</th>\n",
       "      <td>102.660004</td>\n",
       "      <td>104.199997</td>\n",
       "      <td>102.599998</td>\n",
       "      <td>103.800003</td>\n",
       "      <td>103.709198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-27</th>\n",
       "      <td>104.550003</td>\n",
       "      <td>106.330002</td>\n",
       "      <td>104.389999</td>\n",
       "      <td>105.349998</td>\n",
       "      <td>105.257835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-28</th>\n",
       "      <td>105.290001</td>\n",
       "      <td>106.750000</td>\n",
       "      <td>104.730003</td>\n",
       "      <td>105.730003</td>\n",
       "      <td>105.637512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-29</th>\n",
       "      <td>106.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>105.309998</td>\n",
       "      <td>106.279999</td>\n",
       "      <td>106.187027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close\n",
       "Date                                                                  \n",
       "2021-09-23   99.529999  104.080002   99.519997  102.959999  102.789993\n",
       "2021-09-24  102.660004  104.199997  102.599998  103.800003  103.709198\n",
       "2021-09-27  104.550003  106.330002  104.389999  105.349998  105.257835\n",
       "2021-09-28  105.290001  106.750000  104.730003  105.730003  105.637512\n",
       "2021-09-29  106.000000  107.000000  105.309998  106.279999  106.187027"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7395658c-0138-471b-8436-7648fb529eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 5203 entries, 2001-01-25 to 2021-09-29\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Open       5203 non-null   float64\n",
      " 1   High       5203 non-null   float64\n",
      " 2   Low        5203 non-null   float64\n",
      " 3   Close      5203 non-null   float64\n",
      " 4   Adj Close  5203 non-null   float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 243.9 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bc571a-793b-4f6f-9113-7270ba15af02",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e5dbe00-d156-486a-a985-d3c7e80a438c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_for_training,df_for_testing = train_test_split(df,test_size=0.2,shuffle=False) # 时间序列划分时一定要设shuffle=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9c81213-0348-4089-90af-2db3680c5119",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4162, 5)\n",
      "(1041, 5)\n"
     ]
    }
   ],
   "source": [
    "print(df_for_training.shape)\n",
    "print(df_for_testing.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee75eca-bdba-483c-9ccc-8a38ade8b0d0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 准备序列数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed730d91-9fb5-4a86-a836-d65289daf20b",
   "metadata": {},
   "source": [
    "- 数据归一\n",
    "\n",
    "数据范围非常大，并且它们没有在相同的范围内缩放，因此为了避免预测错误，让我们先使用MinMaxScaler缩放数据。(也可以使用StandardScaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a86012c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "df_for_training_scaled = scaler.fit_transform(df_for_training)\n",
    "df_for_testing_scaled=scaler.transform(df_for_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d33a6b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.85398707, 0.86281807, 0.85292546, 0.8403402 , 0.82180889],\n",
       "       [0.85533406, 0.85473269, 0.82623316, 0.8122593 , 0.79289309],\n",
       "       [0.82155169, 0.84260459, 0.81422168, 0.80701755, 0.78749611],\n",
       "       ...,\n",
       "       [0.40689652, 0.40362224, 0.41960282, 0.40436458, 0.7632948 ],\n",
       "       [0.40517242, 0.39995691, 0.41832161, 0.4075738 , 0.76889077],\n",
       "       [0.40862067, 0.39974127, 0.41426436, 0.39880189, 0.75359571]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_for_training_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03b668b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4162, 5) (1041, 5)\n"
     ]
    }
   ],
   "source": [
    "print(df_for_training_scaled.shape,df_for_testing_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918a9441-a26a-464c-8df1-3b41a1cab354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 3 构造批数据\n",
    "\n",
    "# def create_batch_dataset(X, y, train=True, buffer_size=1000, batch_size=128):\n",
    "#     batch_data = tf.data.Dataset.from_tensor_slices((tf.constant(X), tf.constant(y))) # 数据封装，tensor类型\n",
    "#     if train: # 训练集\n",
    "#         return batch_data.cache().shuffle(buffer_size).batch(batch_size)\n",
    "#     else: # 测试集\n",
    "#         return batch_data.batch(batch_size)\n",
    "    \n",
    "# # 训练批数据\n",
    "# train_batch_dataset = create_batch_dataset(train_dataset, train_labels)\n",
    "\n",
    "# # 测试批数据\n",
    "# test_batch_dataset = create_batch_dataset(test_dataset, test_labels, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fa6fcd-52f7-4498-b0da-1536ecdea227",
   "metadata": {},
   "source": [
    "- 准备数据\n",
    "\n",
    "这里用过去n_past个样本来预测当前"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b6a58026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createXY(dataset,n_past):\n",
    "    dataX = []\n",
    "    dataY = []\n",
    "    for i in range(n_past, len(dataset)):\n",
    "            dataX.append(dataset[i - n_past:i, 0:dataset.shape[1]]) # X：过去n_past行，除Open之外的列\n",
    "            dataY.append(dataset[i,0]) # Y：i行，Open列\n",
    "    return np.array(dataX),np.array(dataY)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "18b62d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX,trainY=createXY(df_for_training_scaled,30)\n",
    "testX,testY=createXY(df_for_testing_scaled,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e77d396",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.85398707, 0.86281807, 0.85292546, 0.8403402 , 0.82180889],\n",
       "       [0.85533406, 0.85473269, 0.82623316, 0.8122593 , 0.79289309],\n",
       "       [0.82155169, 0.84260459, 0.81422168, 0.80701755, 0.78749611],\n",
       "       [0.81918098, 0.84303579, 0.82319031, 0.8470261 , 0.8286929 ],\n",
       "       [0.86206895, 0.85769729, 0.84753366, 0.84124952, 0.8227448 ],\n",
       "       [0.85668106, 0.85295391, 0.85479397, 0.84659822, 0.82825271],\n",
       "       [0.85129307, 0.85661925, 0.85372629, 0.84766796, 0.82935384],\n",
       "       [0.8540948 , 0.88249248, 0.85799703, 0.88125807, 0.86394198],\n",
       "       [0.88577588, 0.88227684, 0.88255396, 0.87590928, 0.85843431],\n",
       "       [0.88189657, 0.87602422, 0.87016871, 0.86200256, 0.84411479],\n",
       "       [0.88362063, 0.88357053, 0.87892376, 0.86606763, 0.84829995],\n",
       "       [0.87047413, 0.86200956, 0.84390347, 0.8344031 , 0.81569511],\n",
       "       [0.83857758, 0.87645542, 0.84966903, 0.87398378, 0.85645156],\n",
       "       [0.88168102, 0.88012075, 0.88105913, 0.86649551, 0.84874037],\n",
       "       [0.87090514, 0.86287196, 0.85949177, 0.84724008, 0.82891342],\n",
       "       [0.85237065, 0.88249248, 0.8601324 , 0.88403941, 0.86680588],\n",
       "       [0.85668106, 0.86589053, 0.86248134, 0.8630723 , 0.84521599],\n",
       "       [0.87176726, 0.8870203 , 0.88191333, 0.87783486, 0.86041721],\n",
       "       [0.88254305, 0.89003888, 0.88298101, 0.86949083, 0.85182511],\n",
       "       [0.875     , 0.86955587, 0.85821051, 0.86521178, 0.84741896],\n",
       "       [0.85775864, 0.85877534, 0.83600253, 0.84552848, 0.82715127],\n",
       "       [0.86745685, 0.88055195, 0.86120008, 0.88403941, 0.86680588],\n",
       "       [0.87780172, 0.88033639, 0.87828313, 0.88446729, 0.86724607],\n",
       "       [0.88900862, 0.88551106, 0.84838778, 0.85237489, 0.83420073],\n",
       "       [0.83512929, 0.83872361, 0.83365367, 0.83975181, 0.82120263],\n",
       "       [0.83189656, 0.82988361, 0.82532568, 0.81108261, 0.79168158],\n",
       "       [0.81896551, 0.82341526, 0.82703399, 0.82199401, 0.80649534],\n",
       "       [0.85129307, 0.85015098, 0.84240872, 0.8292683 , 0.81401255],\n",
       "       [0.83448273, 0.84282023, 0.84561178, 0.84124952, 0.82639405],\n",
       "       [0.84913791, 0.84497632, 0.83557547, 0.83889605, 0.82396218]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb95ff35-ead4-45a7-a69c-e0a3f7cb605e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8297413960482309"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bdaf6a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainX Shape--  (4132, 30, 5)\n",
      "trainY Shape--  (4132,)\n",
      "testX Shape--  (1011, 30, 5)\n",
      "testY Shape--  (1011,)\n"
     ]
    }
   ],
   "source": [
    "# 生成4132个序列，每个序列有30个时间步，5个特征\n",
    "print(\"trainX Shape-- \",trainX.shape)\n",
    "print(\"trainY Shape-- \",trainY.shape)\n",
    "print(\"testX Shape-- \",testX.shape)\n",
    "print(\"testY Shape-- \",testY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adf3f58-742d-4d28-afc5-11b2eb1b57f8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 建模"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3964334d-b421-4e33-a49d-c56bcc32bfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras_tuner\n",
    "# from keras_tuner.tuners import Hyperband\n",
    "# from keras_tuner.engine.hyperparameters import HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fd954de8-eac7-49ec-89e2-6bf3a2010f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(optimizer='adam'):\n",
    "    model = Sequential([\n",
    "        LSTM(50,return_sequences=True,input_shape=(30,5)),\n",
    "        LSTM(50),\n",
    "        Dropout(0.2),\n",
    "        Dense(1)  \n",
    "    ])\n",
    "    model.compile(loss = 'mse',optimizer = optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c58ebd13-edb6-4491-9fe6-a66cf9fd5405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用网格搜索，用KerasClassifier或KerasRegressor类包装Keras模型，可将其用于scikit-learn。\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6128e278-8786-47cf-a145-ea5f0684888d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_model = KerasRegressor(build_fn=build_model,verbose=1,validation_data=(testX,testY))\n",
    "grid_model = KerasRegressor(build_model,verbose=1,optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a6331b50-e0a1-4aa7-97b1-b80b83afb321",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parameters = {'batch_size' : [16,20],\n",
    "              'epochs' : [8,10],\n",
    "              'optimizer' : ['adam','Adadelta'] }\n",
    "grid_search  = GridSearchCV(estimator = grid_model,\n",
    "                            param_grid = parameters,\n",
    "                            cv = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1fc54625",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "130/130 [==============================] - 10s 46ms/step - loss: 0.0035 - val_loss: 0.0020\n",
      "Epoch 2/8\n",
      "130/130 [==============================] - 5s 41ms/step - loss: 0.0011 - val_loss: 0.0026\n",
      "Epoch 3/8\n",
      "130/130 [==============================] - 6s 42ms/step - loss: 9.4518e-04 - val_loss: 0.0017\n",
      "Epoch 4/8\n",
      "130/130 [==============================] - 6s 45ms/step - loss: 8.7630e-04 - val_loss: 0.0015\n",
      "Epoch 5/8\n",
      "130/130 [==============================] - 7s 56ms/step - loss: 8.8658e-04 - val_loss: 0.0019\n",
      "Epoch 6/8\n",
      "130/130 [==============================] - 8s 61ms/step - loss: 7.9020e-04 - val_loss: 0.0014\n",
      "Epoch 7/8\n",
      "130/130 [==============================] - 8s 61ms/step - loss: 7.2217e-04 - val_loss: 0.0014\n",
      "Epoch 8/8\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 7.3609e-04 - val_loss: 0.0015\n",
      "130/130 [==============================] - 3s 11ms/step\n",
      "Epoch 1/8\n",
      "130/130 [==============================] - 12s 52ms/step - loss: 0.0091 - val_loss: 0.0020\n",
      "Epoch 2/8\n",
      "130/130 [==============================] - 11s 83ms/step - loss: 0.0030 - val_loss: 3.2023e-04\n",
      "Epoch 3/8\n",
      "130/130 [==============================] - 6s 46ms/step - loss: 0.0026 - val_loss: 3.6245e-04\n",
      "Epoch 4/8\n",
      "130/130 [==============================] - 5s 39ms/step - loss: 0.0024 - val_loss: 2.1448e-04\n",
      "Epoch 5/8\n",
      "130/130 [==============================] - 5s 37ms/step - loss: 0.0024 - val_loss: 2.6911e-04\n",
      "Epoch 6/8\n",
      "130/130 [==============================] - 5s 36ms/step - loss: 0.0022 - val_loss: 1.1845e-04\n",
      "Epoch 7/8\n",
      "130/130 [==============================] - 5s 37ms/step - loss: 0.0019 - val_loss: 2.9314e-04\n",
      "Epoch 8/8\n",
      "130/130 [==============================] - 6s 45ms/step - loss: 0.0021 - val_loss: 1.1130e-04\n",
      "130/130 [==============================] - 3s 10ms/step\n",
      "Epoch 1/8\n",
      "130/130 [==============================] - 11s 51ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 2/8\n",
      "130/130 [==============================] - 6s 46ms/step - loss: 0.0011 - val_loss: 0.0035\n",
      "Epoch 3/8\n",
      "130/130 [==============================] - 14s 106ms/step - loss: 9.9290e-04 - val_loss: 0.0035\n",
      "Epoch 4/8\n",
      "130/130 [==============================] - 6s 49ms/step - loss: 0.0010 - val_loss: 0.0022\n",
      "Epoch 5/8\n",
      "130/130 [==============================] - 9s 70ms/step - loss: 8.5713e-04 - val_loss: 0.0022\n",
      "Epoch 6/8\n",
      "130/130 [==============================] - 6s 47ms/step - loss: 7.3633e-04 - val_loss: 0.0027\n",
      "Epoch 7/8\n",
      "130/130 [==============================] - 5s 42ms/step - loss: 6.9815e-04 - val_loss: 0.0024\n",
      "Epoch 8/8\n",
      "130/130 [==============================] - 5s 40ms/step - loss: 7.2502e-04 - val_loss: 0.0013\n",
      "130/130 [==============================] - 2s 8ms/step\n",
      "Epoch 1/8\n",
      "130/130 [==============================] - 12s 57ms/step - loss: 0.0122 - val_loss: 0.0012\n",
      "Epoch 2/8\n",
      "130/130 [==============================] - 8s 63ms/step - loss: 0.0034 - val_loss: 2.9016e-04\n",
      "Epoch 3/8\n",
      "130/130 [==============================] - 7s 54ms/step - loss: 0.0027 - val_loss: 9.6235e-04\n",
      "Epoch 4/8\n",
      "130/130 [==============================] - 6s 43ms/step - loss: 0.0028 - val_loss: 1.4069e-04\n",
      "Epoch 5/8\n",
      "130/130 [==============================] - 9s 67ms/step - loss: 0.0025 - val_loss: 2.8581e-04\n",
      "Epoch 6/8\n",
      "130/130 [==============================] - 18s 137ms/step - loss: 0.0023 - val_loss: 1.2870e-04\n",
      "Epoch 7/8\n",
      "130/130 [==============================] - 7s 56ms/step - loss: 0.0022 - val_loss: 2.0907e-04\n",
      "Epoch 8/8\n",
      "130/130 [==============================] - 6s 46ms/step - loss: 0.0019 - val_loss: 1.7963e-04\n",
      "130/130 [==============================] - 3s 14ms/step\n",
      "Epoch 1/10\n",
      "130/130 [==============================] - 13s 55ms/step - loss: 0.0078 - val_loss: 0.0016\n",
      "Epoch 2/10\n",
      "130/130 [==============================] - 5s 42ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 3/10\n",
      "130/130 [==============================] - 6s 47ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 4/10\n",
      "130/130 [==============================] - 11s 83ms/step - loss: 9.8916e-04 - val_loss: 0.0012\n",
      "Epoch 5/10\n",
      "130/130 [==============================] - 12s 92ms/step - loss: 9.6004e-04 - val_loss: 0.0010\n",
      "Epoch 6/10\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 9.7811e-04 - val_loss: 8.5962e-04\n",
      "Epoch 7/10\n",
      "130/130 [==============================] - 6s 50ms/step - loss: 8.0974e-04 - val_loss: 0.0017\n",
      "Epoch 8/10\n",
      "130/130 [==============================] - 5s 42ms/step - loss: 7.7192e-04 - val_loss: 0.0013\n",
      "Epoch 9/10\n",
      "130/130 [==============================] - 6s 47ms/step - loss: 7.1762e-04 - val_loss: 7.4787e-04\n",
      "Epoch 10/10\n",
      "130/130 [==============================] - 5s 42ms/step - loss: 7.0156e-04 - val_loss: 5.6749e-04\n",
      "130/130 [==============================] - 3s 10ms/step\n",
      "Epoch 1/10\n",
      "130/130 [==============================] - 11s 53ms/step - loss: 0.0087 - val_loss: 2.6599e-04\n",
      "Epoch 2/10\n",
      "130/130 [==============================] - 6s 43ms/step - loss: 0.0029 - val_loss: 1.5650e-04\n",
      "Epoch 3/10\n",
      "130/130 [==============================] - 6s 49ms/step - loss: 0.0027 - val_loss: 2.7851e-04\n",
      "Epoch 4/10\n",
      "130/130 [==============================] - 6s 49ms/step - loss: 0.0024 - val_loss: 2.4659e-04\n",
      "Epoch 5/10\n",
      "130/130 [==============================] - 7s 50ms/step - loss: 0.0021 - val_loss: 1.6339e-04\n",
      "Epoch 6/10\n",
      "130/130 [==============================] - 8s 62ms/step - loss: 0.0022 - val_loss: 1.2862e-04\n",
      "Epoch 7/10\n",
      "130/130 [==============================] - 10s 78ms/step - loss: 0.0021 - val_loss: 1.2348e-04\n",
      "Epoch 8/10\n",
      "130/130 [==============================] - 12s 93ms/step - loss: 0.0022 - val_loss: 1.0930e-04\n",
      "Epoch 9/10\n",
      "130/130 [==============================] - 7s 56ms/step - loss: 0.0018 - val_loss: 1.4635e-04\n",
      "Epoch 10/10\n",
      "130/130 [==============================] - 6s 46ms/step - loss: 0.0017 - val_loss: 9.8519e-05\n",
      "130/130 [==============================] - 3s 12ms/step\n",
      "Epoch 1/10\n",
      "130/130 [==============================] - 12s 51ms/step - loss: 0.0054 - val_loss: 0.0036\n",
      "Epoch 2/10\n",
      "130/130 [==============================] - 6s 43ms/step - loss: 0.0010 - val_loss: 0.0034\n",
      "Epoch 3/10\n",
      "130/130 [==============================] - 6s 48ms/step - loss: 9.1838e-04 - val_loss: 0.0024\n",
      "Epoch 4/10\n",
      "130/130 [==============================] - 10s 79ms/step - loss: 8.9538e-04 - val_loss: 0.0024\n",
      "Epoch 5/10\n",
      "130/130 [==============================] - 9s 72ms/step - loss: 8.7209e-04 - val_loss: 0.0022\n",
      "Epoch 6/10\n",
      "130/130 [==============================] - 5s 41ms/step - loss: 8.1644e-04 - val_loss: 0.0015\n",
      "Epoch 7/10\n",
      "130/130 [==============================] - 6s 48ms/step - loss: 7.6749e-04 - val_loss: 8.4648e-04\n",
      "Epoch 8/10\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 7.8842e-04 - val_loss: 0.0021\n",
      "Epoch 9/10\n",
      "130/130 [==============================] - 5s 41ms/step - loss: 6.7532e-04 - val_loss: 7.3711e-04\n",
      "Epoch 10/10\n",
      "130/130 [==============================] - 6s 48ms/step - loss: 6.1893e-04 - val_loss: 0.0012\n",
      "130/130 [==============================] - 2s 8ms/step\n",
      "Epoch 1/10\n",
      "130/130 [==============================] - 12s 59ms/step - loss: 0.0112 - val_loss: 7.2564e-04\n",
      "Epoch 2/10\n",
      "130/130 [==============================] - 8s 62ms/step - loss: 0.0031 - val_loss: 5.5591e-04\n",
      "Epoch 3/10\n",
      "130/130 [==============================] - 11s 87ms/step - loss: 0.0027 - val_loss: 6.2773e-04\n",
      "Epoch 4/10\n",
      "130/130 [==============================] - 8s 64ms/step - loss: 0.0024 - val_loss: 7.1829e-04\n",
      "Epoch 5/10\n",
      "130/130 [==============================] - 5s 41ms/step - loss: 0.0023 - val_loss: 2.8134e-04\n",
      "Epoch 6/10\n",
      "130/130 [==============================] - 5s 39ms/step - loss: 0.0022 - val_loss: 2.4571e-04\n",
      "Epoch 7/10\n",
      "130/130 [==============================] - 6s 43ms/step - loss: 0.0021 - val_loss: 4.6149e-04\n",
      "Epoch 8/10\n",
      "130/130 [==============================] - 6s 42ms/step - loss: 0.0022 - val_loss: 2.2263e-04\n",
      "Epoch 9/10\n",
      "130/130 [==============================] - 5s 41ms/step - loss: 0.0018 - val_loss: 2.3633e-04\n",
      "Epoch 10/10\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 0.0018 - val_loss: 2.4816e-04\n",
      "130/130 [==============================] - 2s 9ms/step\n",
      "Epoch 1/8\n",
      "104/104 [==============================] - 15s 105ms/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 2/8\n",
      "104/104 [==============================] - 7s 64ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 3/8\n",
      "104/104 [==============================] - 5s 47ms/step - loss: 9.0842e-04 - val_loss: 0.0013\n",
      "Epoch 4/8\n",
      "104/104 [==============================] - 5s 47ms/step - loss: 9.8908e-04 - val_loss: 0.0013\n",
      "Epoch 5/8\n",
      "104/104 [==============================] - 5s 46ms/step - loss: 8.2494e-04 - val_loss: 0.0019\n",
      "Epoch 6/8\n",
      "104/104 [==============================] - 5s 43ms/step - loss: 8.2536e-04 - val_loss: 0.0011\n",
      "Epoch 7/8\n",
      "104/104 [==============================] - 5s 47ms/step - loss: 7.6718e-04 - val_loss: 9.8159e-04\n",
      "Epoch 8/8\n",
      "104/104 [==============================] - 5s 45ms/step - loss: 7.2536e-04 - val_loss: 9.4772e-04\n",
      "104/104 [==============================] - 2s 11ms/step\n",
      "Epoch 1/8\n",
      "104/104 [==============================] - 12s 66ms/step - loss: 0.0132 - val_loss: 0.0015\n",
      "Epoch 2/8\n",
      "104/104 [==============================] - 8s 81ms/step - loss: 0.0031 - val_loss: 6.1951e-04\n",
      "Epoch 3/8\n",
      "104/104 [==============================] - 8s 77ms/step - loss: 0.0030 - val_loss: 3.0830e-04\n",
      "Epoch 4/8\n",
      "104/104 [==============================] - 5s 49ms/step - loss: 0.0026 - val_loss: 1.9724e-04\n",
      "Epoch 5/8\n",
      "104/104 [==============================] - 5s 46ms/step - loss: 0.0025 - val_loss: 2.4182e-04\n",
      "Epoch 6/8\n",
      "104/104 [==============================] - 5s 46ms/step - loss: 0.0024 - val_loss: 4.1655e-04\n",
      "Epoch 7/8\n",
      "104/104 [==============================] - 5s 44ms/step - loss: 0.0026 - val_loss: 5.7258e-04\n",
      "Epoch 8/8\n",
      "104/104 [==============================] - 5s 44ms/step - loss: 0.0022 - val_loss: 2.6302e-04\n",
      "104/104 [==============================] - 2s 12ms/step\n",
      "Epoch 1/8\n",
      "104/104 [==============================] - 12s 72ms/step - loss: 0.0101 - val_loss: 0.0023\n",
      "Epoch 2/8\n",
      "104/104 [==============================] - 8s 78ms/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 3/8\n",
      "104/104 [==============================] - 5s 53ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 4/8\n",
      "104/104 [==============================] - 4s 41ms/step - loss: 0.0010 - val_loss: 0.0020\n",
      "Epoch 5/8\n",
      "104/104 [==============================] - 4s 42ms/step - loss: 9.1951e-04 - val_loss: 0.0015\n",
      "Epoch 6/8\n",
      "104/104 [==============================] - 4s 39ms/step - loss: 9.6262e-04 - val_loss: 0.0015\n",
      "Epoch 7/8\n",
      "104/104 [==============================] - 4s 42ms/step - loss: 8.5429e-04 - val_loss: 0.0014\n",
      "Epoch 8/8\n",
      "104/104 [==============================] - 6s 58ms/step - loss: 8.2930e-04 - val_loss: 0.0015\n",
      "104/104 [==============================] - 3s 13ms/step\n",
      "Epoch 1/8\n",
      "104/104 [==============================] - 14s 65ms/step - loss: 0.0185 - val_loss: 2.5469e-04\n",
      "Epoch 2/8\n",
      "104/104 [==============================] - 4s 42ms/step - loss: 0.0031 - val_loss: 5.3484e-04\n",
      "Epoch 3/8\n",
      "104/104 [==============================] - 5s 44ms/step - loss: 0.0026 - val_loss: 3.6051e-04\n",
      "Epoch 4/8\n",
      "104/104 [==============================] - 5s 46ms/step - loss: 0.0025 - val_loss: 1.9721e-04\n",
      "Epoch 5/8\n",
      "104/104 [==============================] - 5s 44ms/step - loss: 0.0027 - val_loss: 3.7165e-04\n",
      "Epoch 6/8\n",
      "104/104 [==============================] - 5s 47ms/step - loss: 0.0024 - val_loss: 1.6805e-04\n",
      "Epoch 7/8\n",
      "104/104 [==============================] - 5s 47ms/step - loss: 0.0023 - val_loss: 1.6050e-04\n",
      "Epoch 8/8\n",
      "104/104 [==============================] - 5s 47ms/step - loss: 0.0021 - val_loss: 1.4591e-04\n",
      "104/104 [==============================] - 2s 12ms/step\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 11s 65ms/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 5s 46ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 5s 44ms/step - loss: 9.3438e-04 - val_loss: 0.0018\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 5s 48ms/step - loss: 8.9352e-04 - val_loss: 0.0016\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 5s 49ms/step - loss: 8.4631e-04 - val_loss: 0.0011\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 5s 44ms/step - loss: 8.8068e-04 - val_loss: 0.0010\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 5s 46ms/step - loss: 7.5999e-04 - val_loss: 0.0015\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 6s 56ms/step - loss: 7.4293e-04 - val_loss: 0.0011\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 7s 64ms/step - loss: 6.8208e-04 - val_loss: 0.0015\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 8s 76ms/step - loss: 6.3997e-04 - val_loss: 7.8394e-04\n",
      "104/104 [==============================] - 3s 14ms/step\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 11s 55ms/step - loss: 0.0221 - val_loss: 7.1499e-04\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 4s 43ms/step - loss: 0.0029 - val_loss: 2.1855e-04\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 4s 42ms/step - loss: 0.0028 - val_loss: 2.3513e-04\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 4s 43ms/step - loss: 0.0025 - val_loss: 1.8492e-04\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 5s 48ms/step - loss: 0.0026 - val_loss: 3.0685e-04\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 6s 60ms/step - loss: 0.0025 - val_loss: 2.6971e-04\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 5s 44ms/step - loss: 0.0024 - val_loss: 2.0537e-04\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 5s 45ms/step - loss: 0.0022 - val_loss: 1.4446e-04\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 4s 43ms/step - loss: 0.0021 - val_loss: 1.4112e-04\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 5s 46ms/step - loss: 0.0021 - val_loss: 1.5041e-04\n",
      "104/104 [==============================] - 3s 15ms/step\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 11s 57ms/step - loss: 0.0073 - val_loss: 0.0043\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 5s 46ms/step - loss: 0.0011 - val_loss: 0.0036\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 5s 48ms/step - loss: 9.7933e-04 - val_loss: 0.0033\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 5s 46ms/step - loss: 9.8329e-04 - val_loss: 0.0026\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 5s 49ms/step - loss: 8.6975e-04 - val_loss: 0.0021\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 8s 80ms/step - loss: 8.5215e-04 - val_loss: 0.0019\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 9s 82ms/step - loss: 8.9025e-04 - val_loss: 0.0019\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 6s 55ms/step - loss: 7.6946e-04 - val_loss: 0.0016\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 5s 43ms/step - loss: 7.3255e-04 - val_loss: 0.0012\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 4s 40ms/step - loss: 7.0830e-04 - val_loss: 0.0011\n",
      "104/104 [==============================] - 2s 12ms/step\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 10s 51ms/step - loss: 0.0094 - val_loss: 8.3490e-04\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 5s 45ms/step - loss: 0.0030 - val_loss: 6.7220e-04\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 6s 58ms/step - loss: 0.0026 - val_loss: 2.7189e-04\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 6s 56ms/step - loss: 0.0025 - val_loss: 1.7020e-04\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 8s 76ms/step - loss: 0.0024 - val_loss: 2.9724e-04\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 5s 45ms/step - loss: 0.0022 - val_loss: 4.2511e-04\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 4s 42ms/step - loss: 0.0022 - val_loss: 1.6008e-04\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 5s 45ms/step - loss: 0.0019 - val_loss: 1.2337e-04\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 4s 41ms/step - loss: 0.0022 - val_loss: 3.7251e-04\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 4s 40ms/step - loss: 0.0021 - val_loss: 1.1486e-04\n",
      "104/104 [==============================] - 2s 10ms/step\n",
      "Epoch 1/10\n",
      "259/259 [==============================] - 15s 42ms/step - loss: 0.0087 - val_loss: 2.4774e-04\n",
      "Epoch 2/10\n",
      "259/259 [==============================] - 10s 38ms/step - loss: 0.0019 - val_loss: 2.5254e-04\n",
      "Epoch 3/10\n",
      "259/259 [==============================] - 10s 39ms/step - loss: 0.0017 - val_loss: 1.6471e-04\n",
      "Epoch 4/10\n",
      "259/259 [==============================] - 14s 55ms/step - loss: 0.0015 - val_loss: 2.7959e-04\n",
      "Epoch 5/10\n",
      "259/259 [==============================] - 11s 44ms/step - loss: 0.0016 - val_loss: 1.5643e-04\n",
      "Epoch 6/10\n",
      "259/259 [==============================] - 11s 43ms/step - loss: 0.0014 - val_loss: 2.6061e-04\n",
      "Epoch 7/10\n",
      "259/259 [==============================] - 15s 60ms/step - loss: 0.0012 - val_loss: 2.7357e-04\n",
      "Epoch 8/10\n",
      "259/259 [==============================] - 11s 42ms/step - loss: 0.0011 - val_loss: 1.9455e-04\n",
      "Epoch 9/10\n",
      "259/259 [==============================] - 10s 38ms/step - loss: 0.0010 - val_loss: 1.7977e-04\n",
      "Epoch 10/10\n",
      "259/259 [==============================] - 10s 40ms/step - loss: 9.2116e-04 - val_loss: 1.2285e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=KerasRegressor(model=<function build_model at 0x000001D009814B80>, optimizer='adam'),\n",
       "             param_grid={'batch_size': [16, 20], 'epochs': [8, 10],\n",
       "                         'optimizer': ['adam', 'Adadelta']})"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(trainX,trainY,validation_data=(testX,testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a9e26e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最佳参数：{'batch_size': 16, 'epochs': 10, 'optimizer': 'Adadelta'}\n"
     ]
    }
   ],
   "source": [
    "my_model=grid_search.best_estimator_\n",
    "print(f\"最佳参数：{grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "eeb97d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "# 这里的模型其实已经和sklearn中的模型一样了，所有直接将testX扔进去是可以的\n",
    "prediction=my_model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8699c0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction\n",
      " [0.37862605 0.38234293 0.38587564 ... 0.13034046 0.1329429  0.13605207]\n",
      "\n",
      "Prediction Shape- (1011,)\n"
     ]
    }
   ],
   "source": [
    "print(\"prediction\\n\", prediction)\n",
    "print(\"\\nPrediction Shape-\",prediction.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7734695e-4bfd-4863-ad29-442ba387a6b8",
   "metadata": {},
   "source": [
    "- 将预测结果再缩放回去"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c8c654a6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (1011,1) doesn't match the broadcast shape (1011,5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\SUJAN~1.ISL\\AppData\\Local\\Temp/ipykernel_11732/1176355301.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\env1\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36minverse_transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    527\u001b[0m         )\n\u001b[0;32m    528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 529\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    530\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: non-broadcastable output operand with shape (1011,1) doesn't match the broadcast shape (1011,5)"
     ]
    }
   ],
   "source": [
    "scaler.inverse_transform(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "44862c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将预测结果转回缩放之前（缩放之前是1011*5,但prediction是1011*1，所以要复制5列出来）\n",
    "prediction_copies_array = np.repeat(prediction.reshape((-1,1)),5, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3b00bd6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.37862605, 0.37862605, 0.37862605, 0.37862605, 0.37862605],\n",
       "       [0.38234293, 0.38234293, 0.38234293, 0.38234293, 0.38234293],\n",
       "       [0.38587564, 0.38587564, 0.38587564, 0.38587564, 0.38587564],\n",
       "       ...,\n",
       "       [0.13034046, 0.13034046, 0.13034046, 0.13034046, 0.13034046],\n",
       "       [0.1329429 , 0.1329429 , 0.1329429 , 0.1329429 , 0.1329429 ],\n",
       "       [0.13605207, 0.13605207, 0.13605207, 0.13605207, 0.13605207]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_copies_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "84f2780a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将预测值转回缩放前\n",
    "# pred=scaler.inverse_transform(np.reshape(prediction_copies_array,(len(prediction),5)))[:,0]\n",
    "pred = scaler.inverse_transform(prediction_copies_array)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4ec05dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将验证集的y也转回缩放前\n",
    "original_copies_array = np.repeat(testY.reshape(-1,1),5, axis=-1)\n",
    "original=scaler.inverse_transform(original_copies_array)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "cecfd7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred Values--  [187.06346  188.39009  189.651    ...  98.444595  99.37346  100.4832  ]\n",
      "\n",
      "Original Values--  [191.692307 193.461533 192.307693 ... 104.550003 105.290001 106.      ]\n"
     ]
    }
   ],
   "source": [
    "print(\"Pred Values-- \" ,pred)\n",
    "print(\"\\nOriginal Values-- \",original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9de72d30-be7a-4ea8-b303-575019a32a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score,mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "40d735a1-ecff-4ae0-9ffc-ca9f09ea4564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r^2 值为：  0.9794149303255905\n",
      "mse 值为：  15.650433979692608\n"
     ]
    }
   ],
   "source": [
    "# 计算r2值\n",
    "\n",
    "score_r2 = r2_score(original, pred)\n",
    "score_mse = mean_squared_error(original, pred)\n",
    "print(\"r^2 值为： \", score_r2)\n",
    "print(\"mse 值为： \", score_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "07e37414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "bfa9b94b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(original, color = 'red', label = 'Real  Stock Price')\n",
    "plt.plot(pred, color = 'blue', label = 'Predicted  Stock Price')\n",
    "plt.title(' Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel(' Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d010ca7d-ef9f-4652-a70a-3aca9fc82e75",
   "metadata": {},
   "source": [
    "# 预测未来30天的股价"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ecbf9cbb-ab33-4acd-a440-a93934bf7ab8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 在训练数据中获取最后30天数据\n",
    "df_30_days_past=df.iloc[-30:,:]\n",
    "\n",
    "# 对要预测的数据添加一列Open，值初始化为0\n",
    "df_30_days_future=pd.read_csv(\"test.csv\",parse_dates=[\"Date\"],index_col=[0])\n",
    "df_30_days_future.insert(0,\"Open\",0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "927d0874-b3d7-4ce8-ba57-d5be17695526",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-08-18</th>\n",
       "      <td>101.080002</td>\n",
       "      <td>103.470001</td>\n",
       "      <td>100.760002</td>\n",
       "      <td>101.410004</td>\n",
       "      <td>101.242561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-19</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.820000</td>\n",
       "      <td>98.599998</td>\n",
       "      <td>99.419998</td>\n",
       "      <td>99.255844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-20</th>\n",
       "      <td>99.589996</td>\n",
       "      <td>100.669998</td>\n",
       "      <td>99.099998</td>\n",
       "      <td>100.050003</td>\n",
       "      <td>99.884804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-23</th>\n",
       "      <td>100.599998</td>\n",
       "      <td>101.480003</td>\n",
       "      <td>100.269997</td>\n",
       "      <td>100.970001</td>\n",
       "      <td>100.803284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-24</th>\n",
       "      <td>101.290001</td>\n",
       "      <td>103.510002</td>\n",
       "      <td>101.059998</td>\n",
       "      <td>103.269997</td>\n",
       "      <td>103.099487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-25</th>\n",
       "      <td>103.360001</td>\n",
       "      <td>105.129997</td>\n",
       "      <td>102.550003</td>\n",
       "      <td>104.699997</td>\n",
       "      <td>104.527122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-26</th>\n",
       "      <td>104.459999</td>\n",
       "      <td>104.620003</td>\n",
       "      <td>102.839996</td>\n",
       "      <td>103.379997</td>\n",
       "      <td>103.209305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-27</th>\n",
       "      <td>103.900002</td>\n",
       "      <td>106.150002</td>\n",
       "      <td>103.900002</td>\n",
       "      <td>106.089996</td>\n",
       "      <td>105.914825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-30</th>\n",
       "      <td>106.330002</td>\n",
       "      <td>106.459999</td>\n",
       "      <td>104.800003</td>\n",
       "      <td>105.190002</td>\n",
       "      <td>105.016312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-31</th>\n",
       "      <td>104.940002</td>\n",
       "      <td>106.360001</td>\n",
       "      <td>104.459999</td>\n",
       "      <td>105.410004</td>\n",
       "      <td>105.235954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-01</th>\n",
       "      <td>105.360001</td>\n",
       "      <td>105.470001</td>\n",
       "      <td>103.260002</td>\n",
       "      <td>103.660004</td>\n",
       "      <td>103.488846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-02</th>\n",
       "      <td>104.000000</td>\n",
       "      <td>106.339996</td>\n",
       "      <td>103.980003</td>\n",
       "      <td>106.260002</td>\n",
       "      <td>106.084557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-03</th>\n",
       "      <td>106.000000</td>\n",
       "      <td>107.360001</td>\n",
       "      <td>104.080002</td>\n",
       "      <td>104.750000</td>\n",
       "      <td>104.577042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-07</th>\n",
       "      <td>104.500000</td>\n",
       "      <td>104.940002</td>\n",
       "      <td>102.309998</td>\n",
       "      <td>103.290001</td>\n",
       "      <td>103.119453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-08</th>\n",
       "      <td>102.949997</td>\n",
       "      <td>104.730003</td>\n",
       "      <td>100.419998</td>\n",
       "      <td>102.580002</td>\n",
       "      <td>102.410629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-09</th>\n",
       "      <td>102.360001</td>\n",
       "      <td>104.919998</td>\n",
       "      <td>102.110001</td>\n",
       "      <td>103.290001</td>\n",
       "      <td>103.119453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-10</th>\n",
       "      <td>103.290001</td>\n",
       "      <td>103.949997</td>\n",
       "      <td>101.779999</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>101.831581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-13</th>\n",
       "      <td>102.650002</td>\n",
       "      <td>104.860001</td>\n",
       "      <td>102.019997</td>\n",
       "      <td>104.459999</td>\n",
       "      <td>104.287521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-14</th>\n",
       "      <td>104.540001</td>\n",
       "      <td>104.550003</td>\n",
       "      <td>100.070000</td>\n",
       "      <td>100.379997</td>\n",
       "      <td>100.214256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-15</th>\n",
       "      <td>100.790001</td>\n",
       "      <td>102.470001</td>\n",
       "      <td>100.690002</td>\n",
       "      <td>102.160004</td>\n",
       "      <td>101.991325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-16</th>\n",
       "      <td>102.389999</td>\n",
       "      <td>102.699997</td>\n",
       "      <td>100.820000</td>\n",
       "      <td>101.339996</td>\n",
       "      <td>101.172668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-17</th>\n",
       "      <td>101.150002</td>\n",
       "      <td>101.860001</td>\n",
       "      <td>100.129997</td>\n",
       "      <td>100.470001</td>\n",
       "      <td>100.304115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-20</th>\n",
       "      <td>98.500000</td>\n",
       "      <td>99.870003</td>\n",
       "      <td>97.269997</td>\n",
       "      <td>99.809998</td>\n",
       "      <td>99.645195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-21</th>\n",
       "      <td>99.900002</td>\n",
       "      <td>99.989998</td>\n",
       "      <td>96.209999</td>\n",
       "      <td>96.820000</td>\n",
       "      <td>96.660133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-22</th>\n",
       "      <td>97.669998</td>\n",
       "      <td>99.029999</td>\n",
       "      <td>97.660004</td>\n",
       "      <td>98.540001</td>\n",
       "      <td>98.377296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-23</th>\n",
       "      <td>99.529999</td>\n",
       "      <td>104.080002</td>\n",
       "      <td>99.519997</td>\n",
       "      <td>102.959999</td>\n",
       "      <td>102.789993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-24</th>\n",
       "      <td>102.660004</td>\n",
       "      <td>104.199997</td>\n",
       "      <td>102.599998</td>\n",
       "      <td>103.800003</td>\n",
       "      <td>103.709198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-27</th>\n",
       "      <td>104.550003</td>\n",
       "      <td>106.330002</td>\n",
       "      <td>104.389999</td>\n",
       "      <td>105.349998</td>\n",
       "      <td>105.257835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-28</th>\n",
       "      <td>105.290001</td>\n",
       "      <td>106.750000</td>\n",
       "      <td>104.730003</td>\n",
       "      <td>105.730003</td>\n",
       "      <td>105.637512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-29</th>\n",
       "      <td>106.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>105.309998</td>\n",
       "      <td>106.279999</td>\n",
       "      <td>106.187027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close\n",
       "Date                                                                  \n",
       "2021-08-18  101.080002  103.470001  100.760002  101.410004  101.242561\n",
       "2021-08-19  100.000000  100.820000   98.599998   99.419998   99.255844\n",
       "2021-08-20   99.589996  100.669998   99.099998  100.050003   99.884804\n",
       "2021-08-23  100.599998  101.480003  100.269997  100.970001  100.803284\n",
       "2021-08-24  101.290001  103.510002  101.059998  103.269997  103.099487\n",
       "2021-08-25  103.360001  105.129997  102.550003  104.699997  104.527122\n",
       "2021-08-26  104.459999  104.620003  102.839996  103.379997  103.209305\n",
       "2021-08-27  103.900002  106.150002  103.900002  106.089996  105.914825\n",
       "2021-08-30  106.330002  106.459999  104.800003  105.190002  105.016312\n",
       "2021-08-31  104.940002  106.360001  104.459999  105.410004  105.235954\n",
       "2021-09-01  105.360001  105.470001  103.260002  103.660004  103.488846\n",
       "2021-09-02  104.000000  106.339996  103.980003  106.260002  106.084557\n",
       "2021-09-03  106.000000  107.360001  104.080002  104.750000  104.577042\n",
       "2021-09-07  104.500000  104.940002  102.309998  103.290001  103.119453\n",
       "2021-09-08  102.949997  104.730003  100.419998  102.580002  102.410629\n",
       "2021-09-09  102.360001  104.919998  102.110001  103.290001  103.119453\n",
       "2021-09-10  103.290001  103.949997  101.779999  102.000000  101.831581\n",
       "2021-09-13  102.650002  104.860001  102.019997  104.459999  104.287521\n",
       "2021-09-14  104.540001  104.550003  100.070000  100.379997  100.214256\n",
       "2021-09-15  100.790001  102.470001  100.690002  102.160004  101.991325\n",
       "2021-09-16  102.389999  102.699997  100.820000  101.339996  101.172668\n",
       "2021-09-17  101.150002  101.860001  100.129997  100.470001  100.304115\n",
       "2021-09-20   98.500000   99.870003   97.269997   99.809998   99.645195\n",
       "2021-09-21   99.900002   99.989998   96.209999   96.820000   96.660133\n",
       "2021-09-22   97.669998   99.029999   97.660004   98.540001   98.377296\n",
       "2021-09-23   99.529999  104.080002   99.519997  102.959999  102.789993\n",
       "2021-09-24  102.660004  104.199997  102.599998  103.800003  103.709198\n",
       "2021-09-27  104.550003  106.330002  104.389999  105.349998  105.257835\n",
       "2021-09-28  105.290001  106.750000  104.730003  105.730003  105.637512\n",
       "2021-09-29  106.000000  107.000000  105.309998  106.279999  106.187027"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-09-30</th>\n",
       "      <td>0</td>\n",
       "      <td>107.089996</td>\n",
       "      <td>102.949997</td>\n",
       "      <td>103.029999</td>\n",
       "      <td>102.939865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-01</th>\n",
       "      <td>0</td>\n",
       "      <td>106.389999</td>\n",
       "      <td>103.669998</td>\n",
       "      <td>105.820000</td>\n",
       "      <td>105.727425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-04</th>\n",
       "      <td>0</td>\n",
       "      <td>107.080002</td>\n",
       "      <td>104.599998</td>\n",
       "      <td>104.900002</td>\n",
       "      <td>104.808235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-05</th>\n",
       "      <td>0</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>103.750000</td>\n",
       "      <td>104.900002</td>\n",
       "      <td>104.808235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-06</th>\n",
       "      <td>0</td>\n",
       "      <td>104.419998</td>\n",
       "      <td>102.059998</td>\n",
       "      <td>104.330002</td>\n",
       "      <td>104.238731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-07</th>\n",
       "      <td>0</td>\n",
       "      <td>106.529999</td>\n",
       "      <td>104.330002</td>\n",
       "      <td>105.510002</td>\n",
       "      <td>105.417702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-08</th>\n",
       "      <td>0</td>\n",
       "      <td>106.220001</td>\n",
       "      <td>104.660004</td>\n",
       "      <td>104.720001</td>\n",
       "      <td>104.628387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-11</th>\n",
       "      <td>0</td>\n",
       "      <td>105.760002</td>\n",
       "      <td>103.970001</td>\n",
       "      <td>104.080002</td>\n",
       "      <td>103.988953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-12</th>\n",
       "      <td>0</td>\n",
       "      <td>104.040001</td>\n",
       "      <td>101.559998</td>\n",
       "      <td>102.720001</td>\n",
       "      <td>102.630142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-13</th>\n",
       "      <td>0</td>\n",
       "      <td>103.199997</td>\n",
       "      <td>101.180000</td>\n",
       "      <td>102.360001</td>\n",
       "      <td>102.270454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-14</th>\n",
       "      <td>0</td>\n",
       "      <td>103.650002</td>\n",
       "      <td>102.370003</td>\n",
       "      <td>102.739998</td>\n",
       "      <td>102.650116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-15</th>\n",
       "      <td>0</td>\n",
       "      <td>105.900002</td>\n",
       "      <td>103.190002</td>\n",
       "      <td>104.410004</td>\n",
       "      <td>104.318665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-18</th>\n",
       "      <td>0</td>\n",
       "      <td>104.570000</td>\n",
       "      <td>103.040001</td>\n",
       "      <td>104.120003</td>\n",
       "      <td>104.028915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-19</th>\n",
       "      <td>0</td>\n",
       "      <td>104.970001</td>\n",
       "      <td>103.580002</td>\n",
       "      <td>104.730003</td>\n",
       "      <td>104.638382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-20</th>\n",
       "      <td>0</td>\n",
       "      <td>106.019997</td>\n",
       "      <td>103.870003</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>105.907272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-21</th>\n",
       "      <td>0</td>\n",
       "      <td>106.389999</td>\n",
       "      <td>103.010002</td>\n",
       "      <td>103.150002</td>\n",
       "      <td>103.059761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-22</th>\n",
       "      <td>0</td>\n",
       "      <td>104.510002</td>\n",
       "      <td>102.550003</td>\n",
       "      <td>104.050003</td>\n",
       "      <td>103.958977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-25</th>\n",
       "      <td>0</td>\n",
       "      <td>105.989998</td>\n",
       "      <td>103.330002</td>\n",
       "      <td>105.300003</td>\n",
       "      <td>105.207886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-26</th>\n",
       "      <td>0</td>\n",
       "      <td>110.970001</td>\n",
       "      <td>105.220001</td>\n",
       "      <td>107.440002</td>\n",
       "      <td>107.346008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-27</th>\n",
       "      <td>0</td>\n",
       "      <td>108.279999</td>\n",
       "      <td>103.690002</td>\n",
       "      <td>103.849998</td>\n",
       "      <td>103.759148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-28</th>\n",
       "      <td>0</td>\n",
       "      <td>105.379997</td>\n",
       "      <td>103.099998</td>\n",
       "      <td>105.260002</td>\n",
       "      <td>105.167915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-29</th>\n",
       "      <td>0</td>\n",
       "      <td>105.239998</td>\n",
       "      <td>104.120003</td>\n",
       "      <td>104.870003</td>\n",
       "      <td>104.778259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-01</th>\n",
       "      <td>0</td>\n",
       "      <td>106.769997</td>\n",
       "      <td>105.279999</td>\n",
       "      <td>106.230003</td>\n",
       "      <td>106.137070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-02</th>\n",
       "      <td>0</td>\n",
       "      <td>107.139999</td>\n",
       "      <td>105.300003</td>\n",
       "      <td>106.690002</td>\n",
       "      <td>106.596664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-03</th>\n",
       "      <td>0</td>\n",
       "      <td>106.339996</td>\n",
       "      <td>104.820000</td>\n",
       "      <td>105.970001</td>\n",
       "      <td>105.877296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-04</th>\n",
       "      <td>0</td>\n",
       "      <td>106.400002</td>\n",
       "      <td>104.290001</td>\n",
       "      <td>105.209999</td>\n",
       "      <td>105.117958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-05</th>\n",
       "      <td>0</td>\n",
       "      <td>109.650002</td>\n",
       "      <td>106.849998</td>\n",
       "      <td>108.739998</td>\n",
       "      <td>108.644867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-08</th>\n",
       "      <td>0</td>\n",
       "      <td>110.309998</td>\n",
       "      <td>108.320000</td>\n",
       "      <td>108.419998</td>\n",
       "      <td>108.325150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-09</th>\n",
       "      <td>0</td>\n",
       "      <td>116.169998</td>\n",
       "      <td>110.480003</td>\n",
       "      <td>111.290001</td>\n",
       "      <td>111.192642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-10</th>\n",
       "      <td>0</td>\n",
       "      <td>112.680000</td>\n",
       "      <td>108.110001</td>\n",
       "      <td>108.959999</td>\n",
       "      <td>108.864677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Open        High         Low       Close   Adj Close\n",
       "Date                                                            \n",
       "2021-09-30     0  107.089996  102.949997  103.029999  102.939865\n",
       "2021-10-01     0  106.389999  103.669998  105.820000  105.727425\n",
       "2021-10-04     0  107.080002  104.599998  104.900002  104.808235\n",
       "2021-10-05     0  106.000000  103.750000  104.900002  104.808235\n",
       "2021-10-06     0  104.419998  102.059998  104.330002  104.238731\n",
       "2021-10-07     0  106.529999  104.330002  105.510002  105.417702\n",
       "2021-10-08     0  106.220001  104.660004  104.720001  104.628387\n",
       "2021-10-11     0  105.760002  103.970001  104.080002  103.988953\n",
       "2021-10-12     0  104.040001  101.559998  102.720001  102.630142\n",
       "2021-10-13     0  103.199997  101.180000  102.360001  102.270454\n",
       "2021-10-14     0  103.650002  102.370003  102.739998  102.650116\n",
       "2021-10-15     0  105.900002  103.190002  104.410004  104.318665\n",
       "2021-10-18     0  104.570000  103.040001  104.120003  104.028915\n",
       "2021-10-19     0  104.970001  103.580002  104.730003  104.638382\n",
       "2021-10-20     0  106.019997  103.870003  106.000000  105.907272\n",
       "2021-10-21     0  106.389999  103.010002  103.150002  103.059761\n",
       "2021-10-22     0  104.510002  102.550003  104.050003  103.958977\n",
       "2021-10-25     0  105.989998  103.330002  105.300003  105.207886\n",
       "2021-10-26     0  110.970001  105.220001  107.440002  107.346008\n",
       "2021-10-27     0  108.279999  103.690002  103.849998  103.759148\n",
       "2021-10-28     0  105.379997  103.099998  105.260002  105.167915\n",
       "2021-10-29     0  105.239998  104.120003  104.870003  104.778259\n",
       "2021-11-01     0  106.769997  105.279999  106.230003  106.137070\n",
       "2021-11-02     0  107.139999  105.300003  106.690002  106.596664\n",
       "2021-11-03     0  106.339996  104.820000  105.970001  105.877296\n",
       "2021-11-04     0  106.400002  104.290001  105.209999  105.117958\n",
       "2021-11-05     0  109.650002  106.849998  108.739998  108.644867\n",
       "2021-11-08     0  110.309998  108.320000  108.419998  108.325150\n",
       "2021-11-09     0  116.169998  110.480003  111.290001  111.192642\n",
       "2021-11-10     0  112.680000  108.110001  108.959999  108.864677"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_30_days_past)\n",
    "display(df_30_days_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "7b002847-1826-486d-b6b5-d66ace75ba3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 缩放\n",
    "old_scaled_array=scaler.transform(df_30_days_past)\n",
    "new_scaled_array=scaler.transform(df_30_days_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc40c4f-3524-42f2-8b82-5d0bf5cbf152",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_scaled_array[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "8269943d-d790-47c7-a92f-ea08b3c2231a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.137724</td>\n",
       "      <td>0.135427</td>\n",
       "      <td>0.154363</td>\n",
       "      <td>0.139566</td>\n",
       "      <td>0.329562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.134698</td>\n",
       "      <td>0.127999</td>\n",
       "      <td>0.148366</td>\n",
       "      <td>0.134031</td>\n",
       "      <td>0.319362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.133550</td>\n",
       "      <td>0.127579</td>\n",
       "      <td>0.149754</td>\n",
       "      <td>0.135783</td>\n",
       "      <td>0.322591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.136379</td>\n",
       "      <td>0.129849</td>\n",
       "      <td>0.153002</td>\n",
       "      <td>0.138342</td>\n",
       "      <td>0.327306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.138312</td>\n",
       "      <td>0.135539</td>\n",
       "      <td>0.155195</td>\n",
       "      <td>0.144739</td>\n",
       "      <td>0.339095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.144112</td>\n",
       "      <td>0.140080</td>\n",
       "      <td>0.159332</td>\n",
       "      <td>0.148716</td>\n",
       "      <td>0.346425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.147194</td>\n",
       "      <td>0.138650</td>\n",
       "      <td>0.160137</td>\n",
       "      <td>0.145045</td>\n",
       "      <td>0.339659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.145625</td>\n",
       "      <td>0.142939</td>\n",
       "      <td>0.163079</td>\n",
       "      <td>0.152582</td>\n",
       "      <td>0.353549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.152433</td>\n",
       "      <td>0.143808</td>\n",
       "      <td>0.165578</td>\n",
       "      <td>0.150079</td>\n",
       "      <td>0.348936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.148539</td>\n",
       "      <td>0.143527</td>\n",
       "      <td>0.164634</td>\n",
       "      <td>0.150691</td>\n",
       "      <td>0.350064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.149716</td>\n",
       "      <td>0.141033</td>\n",
       "      <td>0.161303</td>\n",
       "      <td>0.145824</td>\n",
       "      <td>0.341094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.145905</td>\n",
       "      <td>0.143471</td>\n",
       "      <td>0.163301</td>\n",
       "      <td>0.153055</td>\n",
       "      <td>0.354420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.151509</td>\n",
       "      <td>0.146330</td>\n",
       "      <td>0.163579</td>\n",
       "      <td>0.148855</td>\n",
       "      <td>0.346681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.147306</td>\n",
       "      <td>0.139547</td>\n",
       "      <td>0.158665</td>\n",
       "      <td>0.144795</td>\n",
       "      <td>0.339198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.142963</td>\n",
       "      <td>0.138959</td>\n",
       "      <td>0.153419</td>\n",
       "      <td>0.142820</td>\n",
       "      <td>0.335558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.141310</td>\n",
       "      <td>0.139491</td>\n",
       "      <td>0.158110</td>\n",
       "      <td>0.144795</td>\n",
       "      <td>0.339198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.143916</td>\n",
       "      <td>0.136772</td>\n",
       "      <td>0.157194</td>\n",
       "      <td>0.141207</td>\n",
       "      <td>0.332586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.142123</td>\n",
       "      <td>0.139323</td>\n",
       "      <td>0.157860</td>\n",
       "      <td>0.148049</td>\n",
       "      <td>0.345194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.147418</td>\n",
       "      <td>0.138454</td>\n",
       "      <td>0.152447</td>\n",
       "      <td>0.136701</td>\n",
       "      <td>0.324282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.136912</td>\n",
       "      <td>0.132624</td>\n",
       "      <td>0.154168</td>\n",
       "      <td>0.141652</td>\n",
       "      <td>0.333406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.141394</td>\n",
       "      <td>0.133269</td>\n",
       "      <td>0.154529</td>\n",
       "      <td>0.139371</td>\n",
       "      <td>0.329203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.137920</td>\n",
       "      <td>0.130914</td>\n",
       "      <td>0.152614</td>\n",
       "      <td>0.136951</td>\n",
       "      <td>0.324744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.130496</td>\n",
       "      <td>0.125336</td>\n",
       "      <td>0.144674</td>\n",
       "      <td>0.135116</td>\n",
       "      <td>0.321361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.134418</td>\n",
       "      <td>0.125673</td>\n",
       "      <td>0.141732</td>\n",
       "      <td>0.126799</td>\n",
       "      <td>0.306035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.128170</td>\n",
       "      <td>0.122982</td>\n",
       "      <td>0.145757</td>\n",
       "      <td>0.131583</td>\n",
       "      <td>0.314851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.133381</td>\n",
       "      <td>0.137137</td>\n",
       "      <td>0.150920</td>\n",
       "      <td>0.143877</td>\n",
       "      <td>0.337506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.142151</td>\n",
       "      <td>0.137473</td>\n",
       "      <td>0.159470</td>\n",
       "      <td>0.146213</td>\n",
       "      <td>0.342225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.147446</td>\n",
       "      <td>0.143443</td>\n",
       "      <td>0.164439</td>\n",
       "      <td>0.150524</td>\n",
       "      <td>0.350176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.149519</td>\n",
       "      <td>0.144621</td>\n",
       "      <td>0.165383</td>\n",
       "      <td>0.151581</td>\n",
       "      <td>0.352125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.151509</td>\n",
       "      <td>0.145321</td>\n",
       "      <td>0.166993</td>\n",
       "      <td>0.153111</td>\n",
       "      <td>0.354947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-0.145474</td>\n",
       "      <td>0.145574</td>\n",
       "      <td>0.160442</td>\n",
       "      <td>0.144071</td>\n",
       "      <td>0.338276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-0.145474</td>\n",
       "      <td>0.143611</td>\n",
       "      <td>0.162441</td>\n",
       "      <td>0.151831</td>\n",
       "      <td>0.352587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>-0.145474</td>\n",
       "      <td>0.145546</td>\n",
       "      <td>0.165022</td>\n",
       "      <td>0.149273</td>\n",
       "      <td>0.347868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>-0.145474</td>\n",
       "      <td>0.142518</td>\n",
       "      <td>0.162663</td>\n",
       "      <td>0.149273</td>\n",
       "      <td>0.347868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>-0.145474</td>\n",
       "      <td>0.138090</td>\n",
       "      <td>0.157971</td>\n",
       "      <td>0.147687</td>\n",
       "      <td>0.344944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>-0.145474</td>\n",
       "      <td>0.144004</td>\n",
       "      <td>0.164273</td>\n",
       "      <td>0.150969</td>\n",
       "      <td>0.350997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>-0.145474</td>\n",
       "      <td>0.143135</td>\n",
       "      <td>0.165189</td>\n",
       "      <td>0.148772</td>\n",
       "      <td>0.346944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>-0.145474</td>\n",
       "      <td>0.141846</td>\n",
       "      <td>0.163274</td>\n",
       "      <td>0.146992</td>\n",
       "      <td>0.343662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>-0.145474</td>\n",
       "      <td>0.137025</td>\n",
       "      <td>0.156583</td>\n",
       "      <td>0.143209</td>\n",
       "      <td>0.336685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>-0.145474</td>\n",
       "      <td>0.134670</td>\n",
       "      <td>0.155529</td>\n",
       "      <td>0.142208</td>\n",
       "      <td>0.334839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>-0.145474</td>\n",
       "      <td>0.135931</td>\n",
       "      <td>0.158832</td>\n",
       "      <td>0.143265</td>\n",
       "      <td>0.336788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>-0.145474</td>\n",
       "      <td>0.142238</td>\n",
       "      <td>0.161108</td>\n",
       "      <td>0.147910</td>\n",
       "      <td>0.345354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>-0.145474</td>\n",
       "      <td>0.138510</td>\n",
       "      <td>0.160692</td>\n",
       "      <td>0.147103</td>\n",
       "      <td>0.343867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>-0.145474</td>\n",
       "      <td>0.139631</td>\n",
       "      <td>0.162191</td>\n",
       "      <td>0.148800</td>\n",
       "      <td>0.346996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>-0.145474</td>\n",
       "      <td>0.142574</td>\n",
       "      <td>0.162996</td>\n",
       "      <td>0.152332</td>\n",
       "      <td>0.353510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>-0.145474</td>\n",
       "      <td>0.143611</td>\n",
       "      <td>0.160609</td>\n",
       "      <td>0.144405</td>\n",
       "      <td>0.338891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>-0.145474</td>\n",
       "      <td>0.138342</td>\n",
       "      <td>0.159332</td>\n",
       "      <td>0.146908</td>\n",
       "      <td>0.343508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>-0.145474</td>\n",
       "      <td>0.142490</td>\n",
       "      <td>0.161497</td>\n",
       "      <td>0.150385</td>\n",
       "      <td>0.349920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>-0.145474</td>\n",
       "      <td>0.156449</td>\n",
       "      <td>0.166744</td>\n",
       "      <td>0.156337</td>\n",
       "      <td>0.360897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>-0.145474</td>\n",
       "      <td>0.148909</td>\n",
       "      <td>0.162496</td>\n",
       "      <td>0.146352</td>\n",
       "      <td>0.342482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>-0.145474</td>\n",
       "      <td>0.140781</td>\n",
       "      <td>0.160858</td>\n",
       "      <td>0.150274</td>\n",
       "      <td>0.349714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>-0.145474</td>\n",
       "      <td>0.140388</td>\n",
       "      <td>0.163690</td>\n",
       "      <td>0.149189</td>\n",
       "      <td>0.347714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>-0.145474</td>\n",
       "      <td>0.144677</td>\n",
       "      <td>0.166910</td>\n",
       "      <td>0.152972</td>\n",
       "      <td>0.354690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>-0.145474</td>\n",
       "      <td>0.145714</td>\n",
       "      <td>0.166966</td>\n",
       "      <td>0.154251</td>\n",
       "      <td>0.357050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>-0.145474</td>\n",
       "      <td>0.143471</td>\n",
       "      <td>0.165633</td>\n",
       "      <td>0.152249</td>\n",
       "      <td>0.353356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>-0.145474</td>\n",
       "      <td>0.143640</td>\n",
       "      <td>0.164162</td>\n",
       "      <td>0.150135</td>\n",
       "      <td>0.349458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>-0.145474</td>\n",
       "      <td>0.152749</td>\n",
       "      <td>0.171268</td>\n",
       "      <td>0.159953</td>\n",
       "      <td>0.367565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>-0.145474</td>\n",
       "      <td>0.154599</td>\n",
       "      <td>0.175349</td>\n",
       "      <td>0.159063</td>\n",
       "      <td>0.365924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>-0.145474</td>\n",
       "      <td>0.171024</td>\n",
       "      <td>0.181345</td>\n",
       "      <td>0.167045</td>\n",
       "      <td>0.380645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>-0.145474</td>\n",
       "      <td>0.161242</td>\n",
       "      <td>0.174766</td>\n",
       "      <td>0.160565</td>\n",
       "      <td>0.368694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4\n",
       "0   0.137724  0.135427  0.154363  0.139566  0.329562\n",
       "1   0.134698  0.127999  0.148366  0.134031  0.319362\n",
       "2   0.133550  0.127579  0.149754  0.135783  0.322591\n",
       "3   0.136379  0.129849  0.153002  0.138342  0.327306\n",
       "4   0.138312  0.135539  0.155195  0.144739  0.339095\n",
       "5   0.144112  0.140080  0.159332  0.148716  0.346425\n",
       "6   0.147194  0.138650  0.160137  0.145045  0.339659\n",
       "7   0.145625  0.142939  0.163079  0.152582  0.353549\n",
       "8   0.152433  0.143808  0.165578  0.150079  0.348936\n",
       "9   0.148539  0.143527  0.164634  0.150691  0.350064\n",
       "10  0.149716  0.141033  0.161303  0.145824  0.341094\n",
       "11  0.145905  0.143471  0.163301  0.153055  0.354420\n",
       "12  0.151509  0.146330  0.163579  0.148855  0.346681\n",
       "13  0.147306  0.139547  0.158665  0.144795  0.339198\n",
       "14  0.142963  0.138959  0.153419  0.142820  0.335558\n",
       "15  0.141310  0.139491  0.158110  0.144795  0.339198\n",
       "16  0.143916  0.136772  0.157194  0.141207  0.332586\n",
       "17  0.142123  0.139323  0.157860  0.148049  0.345194\n",
       "18  0.147418  0.138454  0.152447  0.136701  0.324282\n",
       "19  0.136912  0.132624  0.154168  0.141652  0.333406\n",
       "20  0.141394  0.133269  0.154529  0.139371  0.329203\n",
       "21  0.137920  0.130914  0.152614  0.136951  0.324744\n",
       "22  0.130496  0.125336  0.144674  0.135116  0.321361\n",
       "23  0.134418  0.125673  0.141732  0.126799  0.306035\n",
       "24  0.128170  0.122982  0.145757  0.131583  0.314851\n",
       "25  0.133381  0.137137  0.150920  0.143877  0.337506\n",
       "26  0.142151  0.137473  0.159470  0.146213  0.342225\n",
       "27  0.147446  0.143443  0.164439  0.150524  0.350176\n",
       "28  0.149519  0.144621  0.165383  0.151581  0.352125\n",
       "29  0.151509  0.145321  0.166993  0.153111  0.354947\n",
       "30 -0.145474  0.145574  0.160442  0.144071  0.338276\n",
       "31 -0.145474  0.143611  0.162441  0.151831  0.352587\n",
       "32 -0.145474  0.145546  0.165022  0.149273  0.347868\n",
       "33 -0.145474  0.142518  0.162663  0.149273  0.347868\n",
       "34 -0.145474  0.138090  0.157971  0.147687  0.344944\n",
       "35 -0.145474  0.144004  0.164273  0.150969  0.350997\n",
       "36 -0.145474  0.143135  0.165189  0.148772  0.346944\n",
       "37 -0.145474  0.141846  0.163274  0.146992  0.343662\n",
       "38 -0.145474  0.137025  0.156583  0.143209  0.336685\n",
       "39 -0.145474  0.134670  0.155529  0.142208  0.334839\n",
       "40 -0.145474  0.135931  0.158832  0.143265  0.336788\n",
       "41 -0.145474  0.142238  0.161108  0.147910  0.345354\n",
       "42 -0.145474  0.138510  0.160692  0.147103  0.343867\n",
       "43 -0.145474  0.139631  0.162191  0.148800  0.346996\n",
       "44 -0.145474  0.142574  0.162996  0.152332  0.353510\n",
       "45 -0.145474  0.143611  0.160609  0.144405  0.338891\n",
       "46 -0.145474  0.138342  0.159332  0.146908  0.343508\n",
       "47 -0.145474  0.142490  0.161497  0.150385  0.349920\n",
       "48 -0.145474  0.156449  0.166744  0.156337  0.360897\n",
       "49 -0.145474  0.148909  0.162496  0.146352  0.342482\n",
       "50 -0.145474  0.140781  0.160858  0.150274  0.349714\n",
       "51 -0.145474  0.140388  0.163690  0.149189  0.347714\n",
       "52 -0.145474  0.144677  0.166910  0.152972  0.354690\n",
       "53 -0.145474  0.145714  0.166966  0.154251  0.357050\n",
       "54 -0.145474  0.143471  0.165633  0.152249  0.353356\n",
       "55 -0.145474  0.143640  0.164162  0.150135  0.349458\n",
       "56 -0.145474  0.152749  0.171268  0.159953  0.367565\n",
       "57 -0.145474  0.154599  0.175349  0.159063  0.365924\n",
       "58 -0.145474  0.171024  0.181345  0.167045  0.380645\n",
       "59 -0.145474  0.161242  0.174766  0.160565  0.368694"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.vstack((old_scaled_array,new_scaled_array)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "32e82d4f-dc1f-4f00-ab1c-0166725506c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_90708/2660075960.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mold_scaled_array\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnew_scaled_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "np.concatenate(old_scaled_array,new_scaled_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "22bd73ba-d9ad-4f67-a1ab-f336c40c9557",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.14547414,  0.14557351,  0.16044202,  0.14407146,  0.33827558],\n",
       "       [-0.14547414,  0.14361147,  0.16244074,  0.15183141,  0.35258691],\n",
       "       [-0.14547414,  0.1455455 ,  0.16502242,  0.14927258,  0.34786779],\n",
       "       [-0.14547414,  0.14251833,  0.16266282,  0.14927258,  0.34786779],\n",
       "       [-0.14547414,  0.13808969,  0.15797138,  0.14768721,  0.34494396],\n",
       "       [-0.14547414,  0.14400388,  0.16427291,  0.1509692 ,  0.3509968 ],\n",
       "       [-0.14547414,  0.14313498,  0.16518899,  0.14877193,  0.34694445],\n",
       "       [-0.14547414,  0.14184563,  0.16327354,  0.14699188,  0.3436616 ],\n",
       "       [-0.14547414,  0.13702458,  0.15658338,  0.14320925,  0.33668547],\n",
       "       [-0.14547414,  0.13467011,  0.15552851,  0.14220796,  0.33483883],\n",
       "       [-0.14547414,  0.13593144,  0.15883195,  0.14326486,  0.33678801],\n",
       "       [-0.14547414,  0.14223804,  0.16110827,  0.14790972,  0.34535434],\n",
       "       [-0.14547414,  0.13851014,  0.16069187,  0.14710313,  0.34386677],\n",
       "       [-0.14547414,  0.13963131,  0.16219091,  0.14879975,  0.34699577],\n",
       "       [-0.14547414,  0.14257438,  0.16299595,  0.15233205,  0.35351025],\n",
       "       [-0.14547414,  0.14361147,  0.16060859,  0.14440523,  0.33889113],\n",
       "       [-0.14547414,  0.13834197,  0.15933163,  0.14690844,  0.3435077 ],\n",
       "       [-0.14547414,  0.14249029,  0.16149691,  0.15038512,  0.3499196 ],\n",
       "       [-0.14547414,  0.15644891,  0.16674354,  0.15633719,  0.36089672],\n",
       "       [-0.14547414,  0.14890901,  0.16249627,  0.14635216,  0.34248178],\n",
       "       [-0.14547414,  0.1407805 ,  0.16085842,  0.15027386,  0.34971439],\n",
       "       [-0.14547414,  0.1403881 ,  0.16368995,  0.14918914,  0.3477139 ],\n",
       "       [-0.14547414,  0.14467658,  0.1669101 ,  0.15297177,  0.35469003],\n",
       "       [-0.14547414,  0.14571367,  0.16696563,  0.15425118,  0.35704959],\n",
       "       [-0.14547414,  0.14347132,  0.16563314,  0.15224861,  0.35335635],\n",
       "       [-0.14547414,  0.14363951,  0.16416186,  0.15013479,  0.34945791],\n",
       "       [-0.14547414,  0.15274904,  0.17126841,  0.15995293,  0.36756506],\n",
       "       [-0.14547414,  0.15459896,  0.17534913,  0.1590629 ,  0.36592363],\n",
       "       [-0.14547414,  0.17102415,  0.1813453 ,  0.16704536,  0.38064533],\n",
       "       [-0.14547414,  0.16124192,  0.17476618,  0.16056482,  0.36869356]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "new_scaled_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4fb49a83-bf17-4de5-a59c-040b319503fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_scaled_df=pd.DataFrame(new_scaled_array)\n",
    "new_scaled_df.iloc[:,0]=np.nan\n",
    "full_df=pd.concat([pd.DataFrame(old_scaled_array),new_scaled_df]).reset_index().drop([\"index\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0dcb1ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 5)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "88cfa224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.143640</td>\n",
       "      <td>0.164162</td>\n",
       "      <td>0.150135</td>\n",
       "      <td>0.349458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.152749</td>\n",
       "      <td>0.171268</td>\n",
       "      <td>0.159953</td>\n",
       "      <td>0.367565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.154599</td>\n",
       "      <td>0.175349</td>\n",
       "      <td>0.159063</td>\n",
       "      <td>0.365924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.171024</td>\n",
       "      <td>0.181345</td>\n",
       "      <td>0.167045</td>\n",
       "      <td>0.380645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.161242</td>\n",
       "      <td>0.174766</td>\n",
       "      <td>0.160565</td>\n",
       "      <td>0.368694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         1         2         3         4\n",
       "55 NaN  0.143640  0.164162  0.150135  0.349458\n",
       "56 NaN  0.152749  0.171268  0.159953  0.367565\n",
       "57 NaN  0.154599  0.175349  0.159063  0.365924\n",
       "58 NaN  0.171024  0.181345  0.167045  0.380645\n",
       "59 NaN  0.161242  0.174766  0.160565  0.368694"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e8cc462a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 5)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "48bf070f",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df_scaled_array=full_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "91fdcf82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 5)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df_scaled_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "547622aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data=[]\n",
    "time_step=30\n",
    "for i in range(time_step,len(full_df_scaled_array)):\n",
    "    data_x=[]\n",
    "    data_x.append(full_df_scaled_array[i-time_step:i,0:full_df_scaled_array.shape[1]])\n",
    "    data_x=np.array(data_x)\n",
    "    prediction=my_model.predict(data_x)\n",
    "    all_data.append(prediction)\n",
    "    full_df.iloc[i,0]=prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "05929d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.1378213]], dtype=float32),\n",
       " array([[0.13945529]], dtype=float32),\n",
       " array([[0.14068112]], dtype=float32),\n",
       " array([[0.14162877]], dtype=float32),\n",
       " array([[0.14216018]], dtype=float32),\n",
       " array([[0.14206707]], dtype=float32),\n",
       " array([[0.1421535]], dtype=float32),\n",
       " array([[0.14225037]], dtype=float32),\n",
       " array([[0.14217126]], dtype=float32),\n",
       " array([[0.14150538]], dtype=float32),\n",
       " array([[0.14047278]], dtype=float32),\n",
       " array([[0.13954498]], dtype=float32),\n",
       " array([[0.13914707]], dtype=float32),\n",
       " array([[0.13891666]], dtype=float32),\n",
       " array([[0.13893819]], dtype=float32),\n",
       " array([[0.13930015]], dtype=float32),\n",
       " array([[0.13948296]], dtype=float32),\n",
       " array([[0.13946058]], dtype=float32),\n",
       " array([[0.13963053]], dtype=float32),\n",
       " array([[0.14062819]], dtype=float32),\n",
       " array([[0.14126904]], dtype=float32),\n",
       " array([[0.14153312]], dtype=float32),\n",
       " array([[0.1416432]], dtype=float32),\n",
       " array([[0.14201452]], dtype=float32),\n",
       " array([[0.14254372]], dtype=float32),\n",
       " array([[0.14292328]], dtype=float32),\n",
       " array([[0.14306733]], dtype=float32),\n",
       " array([[0.14389662]], dtype=float32),\n",
       " array([[0.14515653]], dtype=float32),\n",
       " array([[0.14742556]], dtype=float32)]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "379cf40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_array=np.array(all_data)\n",
    "new_array=new_array.reshape(-1,1)\n",
    "prediction_copies_array = np.repeat(new_array,5, axis=-1)\n",
    "y_pred_future_30_days = scaler.inverse_transform(np.reshape(prediction_copies_array,(len(new_array),5)))[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4ab9307c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([101.11468 , 101.69789 , 102.135414, 102.473656, 102.66332 ,\n",
       "       102.6301  , 102.66094 , 102.69551 , 102.66728 , 102.4296  ,\n",
       "       102.06105 , 101.7299  , 101.58788 , 101.50563 , 101.51332 ,\n",
       "       101.64251 , 101.70776 , 101.69977 , 101.76044 , 102.11652 ,\n",
       "       102.34525 , 102.43951 , 102.478806, 102.61133 , 102.80022 ,\n",
       "       102.93569 , 102.98711 , 103.2831  , 103.732796, 104.54266 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_future_30_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265bfef0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed9c5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ede34e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel.save('Model_future_value.h5')\n",
    "print('Model Saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f12ddc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f766d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "scalerfile = 'scaler_model_future_value.pkl'\n",
    "pickle.dump(scaler, open(scalerfile, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbe5698",
   "metadata": {},
   "source": [
    "# END!!!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
